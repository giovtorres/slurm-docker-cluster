# Multi-stage Dockerfile for Slurm runtime with NVIDIA GPU support
# Stage 1: Build RPMs using the builder image
# Stage 2: Install RPMs in a clean runtime image with NVIDIA support

ARG SLURM_VERSION

# ============================================================================
# Stage 1: Build RPMs
# ============================================================================
FROM rockylinux/rockylinux:9 AS builder

ARG SLURM_VERSION

# Enable CRB and EPEL repositories for development packages
RUN set -ex \
    && dnf makecache \
    && dnf -y update \
    && dnf -y install dnf-plugins-core epel-release \
    && dnf config-manager --set-enabled crb \
    && dnf makecache

# Install RPM build tools and dependencies
RUN set -ex \
    && dnf -y install \
       autoconf \
       automake \
       bzip2 \
       freeipmi-devel \
       dbus-devel \
       gcc \
       gcc-c++ \
       git \
       gtk2-devel \
       hdf5-devel \
       http-parser-devel \
       hwloc-devel \
       json-c-devel \
       libcurl-devel \
       libyaml-devel \
       lua-devel \
       lz4-devel \
       make \
       man2html \
       mariadb-devel \
       munge \
       munge-devel \
       ncurses-devel \
       numactl-devel \
       openssl-devel \
       pam-devel \
       perl \
       python3 \
       python3-devel \
       readline-devel \
       rpm-build \
       rpmdevtools \
       rrdtool-devel \
       wget \
    && dnf clean all \
    && rm -rf /var/cache/dnf

# Setup RPM build environment
RUN rpmdev-setuptree

# Copy RPM macros
COPY rpmbuild/slurm.rpmmacros /root/.rpmmacros

# Download official Slurm release tarball and build RPMs with slurmrestd enabled
RUN set -ex \
    && wget -O /root/rpmbuild/SOURCES/slurm-${SLURM_VERSION}.tar.bz2 \
       https://download.schedmd.com/slurm/slurm-${SLURM_VERSION}.tar.bz2 \
    && cd /root/rpmbuild/SOURCES \
    && rpmbuild -ta slurm-${SLURM_VERSION}.tar.bz2 \
    && ls -lh /root/rpmbuild/RPMS/x86_64/

# ============================================================================
# Stage 2: Runtime image with NVIDIA GPU support
# ============================================================================
FROM rockylinux/rockylinux:9

LABEL org.opencontainers.image.source="https://github.com/giovtorres/slurm-docker-cluster" \
      org.opencontainers.image.title="slurm-docker-cluster-gpu" \
      org.opencontainers.image.description="Slurm Docker cluster on Rocky Linux 9 with NVIDIA GPU support" \
      maintainer="Giovanni Torres"

ARG SLURM_VERSION

# Enable CRB and EPEL repositories for runtime dependencies
RUN set -ex \
    && dnf makecache \
    && dnf -y update \
    && dnf -y install dnf-plugins-core epel-release \
    && dnf config-manager --set-enabled crb \
    && dnf makecache

# Install runtime dependencies only
RUN set -ex \
    && dnf -y install \
       bash-completion \
       bzip2 \
       gettext \
       hdf5 \
       http-parser \
       hwloc \
       json-c \
       jq \
       libaec \
       libyaml \
       lua \
       lz4 \
       mariadb \
       munge \
       numactl \
       perl \
       procps-ng \
       psmisc \
       python3 \
       readline \
       vim-enhanced \
       wget \
    && dnf clean all \
    && rm -rf /var/cache/dnf

# Add NVIDIA repositories and disable all GPG checks
RUN set -ex \
    && dnf config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/cuda-rhel9.repo \
    && curl -s -L https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo \
       | tee /etc/yum.repos.d/nvidia-container-toolkit.repo \
    && sed -i -e 's/^gpgcheck=1/gpgcheck=0/' -e 's/^repo_gpgcheck=1/repo_gpgcheck=0/' /etc/yum.repos.d/nvidia-container-toolkit.repo \
    && cat /etc/yum.repos.d/nvidia-container-toolkit.repo \
    && dnf makecache

# Install NVIDIA Container Toolkit and CUDA toolkit
RUN set -ex \
    && dnf -y install \
       nvidia-container-toolkit \
       cuda-toolkit-12-6 \
    && dnf clean all \
    && rm -rf /var/cache/dnf

# Configure NVIDIA Container Runtime
RUN nvidia-ctk runtime configure --runtime=docker

# Install gosu for privilege dropping
ARG GOSU_VERSION=1.19

RUN set -ex \
    && wget -O /usr/local/bin/gosu "https://github.com/tianon/gosu/releases/download/$GOSU_VERSION/gosu-amd64" \
    && wget -O /usr/local/bin/gosu.asc "https://github.com/tianon/gosu/releases/download/$GOSU_VERSION/gosu-amd64.asc" \
    && export GNUPGHOME="$(mktemp -d)" \
    && gpg --batch --keyserver hkps://keys.openpgp.org --recv-keys B42F6819007F00F88E364FD4036A9C25BF357DD4 \
    && gpg --batch --verify /usr/local/bin/gosu.asc /usr/local/bin/gosu \
    && rm -rf "${GNUPGHOME}" /usr/local/bin/gosu.asc \
    && chmod +x /usr/local/bin/gosu \
    && gosu nobody true

# Copy Slurm RPMs from builder stage
COPY --from=builder /root/rpmbuild/RPMS/x86_64/*.rpm /tmp/rpms/

# Install Slurm RPMs
RUN set -ex \
    && dnf -y install /tmp/rpms/slurm-[0-9]*.rpm \
       /tmp/rpms/slurm-perlapi-*.rpm \
       /tmp/rpms/slurm-slurmctld-*.rpm \
       /tmp/rpms/slurm-slurmd-*.rpm \
       /tmp/rpms/slurm-slurmdbd-*.rpm \
       /tmp/rpms/slurm-slurmrestd-*.rpm \
       /tmp/rpms/slurm-contribs-*.rpm \
    && rm -rf /tmp/rpms \
    && dnf clean all

# Create slurm user and group
RUN set -x \
    && groupadd -r --gid=990 slurm \
    && useradd -r -g slurm --uid=990 slurm \
    && groupadd -r --gid=991 slurmrest \
    && useradd -r -g slurmrest --uid=991 slurmrest

# Fix /etc permissions and create munge key
RUN set -x \
    && chmod 0755 /etc \
    && /sbin/create-munge-key

# Create slurm dirs with correct ownership
RUN set -x \
    && mkdir -m 0755 -p \
        /var/run/slurm \
        /var/spool/slurm \
        /var/lib/slurm \
        /var/log/slurm \
        /etc/slurm \
    && chown slurm:slurm \
        /var/run/slurm \
        /var/spool/slurm \
        /var/lib/slurm \
        /var/log/slurm \
        /etc/slurm

# Copy Slurm configuration files
# Version-specific configs: Extract major.minor from SLURM_VERSION (e.g., "24.11" from "24.11.6")
COPY config/ /tmp/slurm-config/
RUN set -ex \
    && MAJOR_MINOR=$(echo ${SLURM_VERSION} | cut -d. -f1,2) \
    && echo "Detected Slurm version: ${MAJOR_MINOR}" \
    # slurm.conf (always required)
    && if [ -f "/tmp/slurm-config/${MAJOR_MINOR}/slurm.conf" ]; then \
         echo "Using version-specific slurm.conf for ${MAJOR_MINOR}"; \
         cp /tmp/slurm-config/${MAJOR_MINOR}/slurm.conf /etc/slurm/slurm.conf; \
       else \
         echo "No version-specific slurm.conf found for ${MAJOR_MINOR}, using 25.05"; \
         cp /tmp/slurm-config/25.05/slurm.conf /etc/slurm/slurm.conf; \
       fi \
    # slurmdbd.conf (always copied)
    && cp /tmp/slurm-config/common/slurmdbd.conf /etc/slurm/slurmdbd.conf \
    # cgroup.conf (OPTIONAL)
    && if [ -f "/tmp/slurm-config/${MAJOR_MINOR}/cgroup.conf" ]; then \
         echo "Using version-specific cgroup.conf for ${MAJOR_MINOR}"; \
         cp /tmp/slurm-config/${MAJOR_MINOR}/cgroup.conf /etc/slurm/cgroup.conf; \
       elif [ -f "/tmp/slurm-config/common/cgroup.conf" ]; then \
         echo "Using common cgroup.conf"; \
         cp /tmp/slurm-config/common/cgroup.conf /etc/slurm/cgroup.conf; \
       else \
         echo "No cgroup.conf found; skipping (disables Slurm cgroup plugin)"; \
       fi \
    # gres.conf (OPTIONAL)
    && if [ -f "/tmp/slurm-config/${MAJOR_MINOR}/gres.conf" ]; then \
         echo "Using version-specific gres.conf for ${MAJOR_MINOR}"; \
         cp /tmp/slurm-config/${MAJOR_MINOR}/gres.conf /etc/slurm/gres.conf; \
       elif [ -f "/tmp/slurm-config/common/gres.conf" ]; then \
         echo "Using common gres.conf"; \
         cp /tmp/slurm-config/common/gres.conf /etc/slurm/gres.conf; \
       else \
         echo "No gres.conf found; skipping"; \
       fi \
    # ownership & permissions (guarded)
    && chown slurm:slurm /etc/slurm/slurm.conf /etc/slurm/slurmdbd.conf \
    && chmod 644 /etc/slurm/slurm.conf \
    && chmod 600 /etc/slurm/slurmdbd.conf \
    && [ -f /etc/slurm/cgroup.conf ] && chown slurm:slurm /etc/slurm/cgroup.conf && chmod 644 /etc/slurm/cgroup.conf || true \
    && [ -f /etc/slurm/gres.conf ]   && chown slurm:slurm /etc/slurm/gres.conf   && chmod 644 /etc/slurm/gres.conf   || true \
    && rm -rf /tmp/slurm-config

COPY --chown=slurm:slurm --chmod=0600 examples /root/examples

# Copy entrypoint script
COPY docker-entrypoint.sh /usr/local/bin/docker-entrypoint.sh
RUN chmod +x /usr/local/bin/docker-entrypoint.sh

# GPU-specific environment variables
ENV NVIDIA_VISIBLE_DEVICES=all
ENV NVIDIA_DRIVER_CAPABILITIES=compute,utility

# Prefer CUDA 12.6 without changing /usr/local/cuda
ENV CUDA_HOME=/usr/local/cuda-12.6
ENV PATH=${CUDA_HOME}/bin:${PATH}
ENV LD_LIBRARY_PATH=${CUDA_HOME}/lib64:${CUDA_HOME}/targets/x86_64-linux/lib:${LD_LIBRARY_PATH}
RUN printf "/usr/local/cuda-12.6/lib64\n/usr/local/cuda-12.6/targets/x86_64-linux/lib\n" \
    > /etc/ld.so.conf.d/cuda-12.6.conf && ldconfig

ENTRYPOINT ["/usr/local/bin/docker-entrypoint.sh"]

CMD ["slurmdbd"]
